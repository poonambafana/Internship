{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0594a7f7",
   "metadata": {},
   "source": [
    "1. Write a python program which searches all the product under a particular product from www.amazon.in. The product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for guitars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d76f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d67b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium\n",
    "!pip install webdriver-manager\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "driver=webdriver.Chrome(ChromeDriverManager().install())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce1fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.amazon.in/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e88943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "I1=input(\"what catogary you want to search \")\n",
    "button=driver.find_element_by_xpath('//*[@id=\"searchDropdownBox\"]')\n",
    "button.send_keys(I1)\n",
    "I2=input(\"what product you want to search\")\n",
    "search_bar=driver.find_element_by_xpath('//*[@id=\"twotabsearchtextbox\"]')\n",
    "search_bar.send_keys(I2)\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the button and clicking it toh search for sunglasses\n",
    "button2=driver.find_element_by_xpath('//*[@id=\"nav-search-bar-form\"]/div[3]/div')\n",
    "button2.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7e1caa",
   "metadata": {},
   "source": [
    "2. In the above question, now scrape the following details of each product listed in first 3 pages of your \n",
    "search results and save it in a data frame and csv. In case if any product has less than 3 pages in search \n",
    "results then scrape all the products available under that product name. Details to be scraped are: \"Brand \n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and \n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275124a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "price=[]\n",
    "Delivery=[]\n",
    "URL=[]\n",
    "\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):#for loop for scrapping 4 page\n",
    "    brands=driver.find_elements_by_xpath(\"//span[@class='a-size-base-plus a-color-base a-text-normal']\")\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    brand1=brand[0:50]\n",
    "    \n",
    "    prices=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")# scraping the price from the xpath\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    price1=price[0:50]\n",
    "    \n",
    "    delivery=driver.find_elements_by_xpath(\"//span[@class='a-color-base a-text-bold']\")# scraping the price from the xpath\n",
    "    for i in delivery:\n",
    "        Delivery.append(i.text)\n",
    "    Delivery1=Delivery[0:50]\n",
    "    \n",
    "    urls=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal']\")\n",
    "    for i in urls:\n",
    "        URL.append(i.get_attribute('href'))\n",
    "    URL1=URL[0:50]\n",
    "    \n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='s-pagination-item s-pagination-next s-pagination-button s-pagination-separator']\")\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c78784",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Brand':brand1,'Price':price1,'Delivery':Delivery1,'URL':URL1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf00a5c",
   "metadata": {},
   "source": [
    "3. Write a python program to access the search bar and search button on images.google.com and scrape 10\n",
    "    images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cdbf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='http://images.google.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd7679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=['fruits','cars','Machine Learning','Guitar','Cakes']\n",
    "for j in Data:\n",
    "    button=driver.find_element_by_xpath('//*[@id=\"sbtc\"]/div/div[2]/input')\n",
    "    button.send_keys(j)\n",
    "    button=driver.find_element_by_xpath('//*[@id=\"sbtc\"]/button')\n",
    "    button.click()\n",
    "    image=[]\n",
    "    images=driver.find_elements_by_xpath(\"//img[contains(@class,'rg_i Q4LuWd')]\")\n",
    "    for i in images:\n",
    "    image.append(i.get_attribute('src'))\n",
    "    \n",
    "    image[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a93ef8",
   "metadata": {},
   "source": [
    "4  Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on\n",
    "www.flipkart.com and scrape following details for all the search results displayed on 1st page. Details to be \n",
    "scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”, \n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the \n",
    "details is missing then replace it by “- “. Save your results in a dataframe and CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d48acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10cb823",
   "metadata": {},
   "outputs": [],
   "source": [
    "button=driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "button.send_keys('vivo smartphones')\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the button and clicking it toh search for sunglasses\n",
    "button2=driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "button2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9532b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_name_color=[]\n",
    "RAMROM=[]\n",
    "Camera=[]\n",
    "display=[]\n",
    "battery=[]\n",
    "price=[]\n",
    "url=[]\n",
    "\n",
    "brands=driver.find_elements_by_xpath(\"//div[@class='_4rR01T']\")\n",
    "for i in brands:\n",
    "    brand_name_color.append(i.text)\n",
    "    \n",
    "prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3 _1_WHN1']\")\n",
    "for i in prices:\n",
    "    price.append(i.text)\n",
    "    \n",
    "ram=driver.find_elements_by_xpath(\"//li[@class='rgWa7D']\")\n",
    "for i in ram:\n",
    "    RAMROM.append(i.text)\n",
    "RAMROM1=RAMROM[0:66:6]\n",
    "RAMROM2=RAMROM[68:144:6]\n",
    "RAMROM3=RAMROM1+RAMROM2\n",
    "\n",
    "camera=driver.find_elements_by_xpath(\"//li[@class='rgWa7D']\")\n",
    "for i in camera:\n",
    "    Camera.append(i.text)#appending the text in Brand list\n",
    "Camera1=Camera[2:72:6]\n",
    "Camera2=Camera[75:144:6]\n",
    "Camera3=Camera1+Camera2\n",
    "\n",
    "size=driver.find_elements_by_xpath(\"//li[@class='rgWa7D']\")\n",
    "for i in size:\n",
    "    display.append(i.text)\n",
    "display1=display[1:67:6]\n",
    "display2=display[68:144:6]\n",
    "display3=display1+display2\n",
    "\n",
    "size=driver.find_elements_by_xpath(\"//li[@class='rgWa7D']\")\n",
    "for i in size:\n",
    "    battery.append(i.text)\n",
    "battery1=battery[3:67:6]\n",
    "battery2=battery[70:144:6]\n",
    "battery3=battery1+battery2\n",
    "\n",
    "url_=driver.find_elements_by_xpath(\"//a[@class='_1fQZEK']\")\n",
    "for i in url_:\n",
    "    url.append(i.get_attribute('href'))\n",
    "    \n",
    "Phone=pd.DataFrame({'Brand,Name,Color':brand_name_color,'RAM ROM':RAMROM3,'Camera':Camera3,'Display':display3,'Battery':battery3,'price':price,'URL':url})\n",
    "Phone.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aea7b3d",
   "metadata": {},
   "source": [
    "5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbf79ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://maps.google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700d5b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchplace():\n",
    "    Place = driver.find_element_by_xpath('//*[@id=\"searchboxinput\"]')\n",
    "    Place.send_keys(\"Pune\")\n",
    "    Submit = driver.find_element_by_xpath('//*[@id=\"searchbox-searchbutton\"]')\n",
    "    Submit.click()\n",
    "  \n",
    "searchplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1416afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_Lat=[]\n",
    "log_lat=driver.find_elements_by_xpath(\"//button[@class='nGhxh-tv6Bve GaSlwc-uhFGfc-WsjYwc-zfKixb-UacCoe']\")\n",
    "for i in log_lat:\n",
    "    Log_Lat.append(i.text)\n",
    "Log_Lat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ff8e8c",
   "metadata": {},
   "source": [
    "6. Write a program to scrap details of all the funding deals for second quarter (i.e Jan 21 – March 21) from trak.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd6ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.trak.in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b25beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "button=driver.find_element_by_xpath('//*[@id=\"main-navigation\"]/li[7]')\n",
    "button.click()\n",
    "button1=driver.find_element_by_xpath('//*[@id=\"menu-item-51510\"]')\n",
    "button1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3253c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_no=[]\n",
    "s_no=driver.find_elements_by_xpath(\"//td[@class='column-1']\")\n",
    "for i in s_no:\n",
    "    S_no.append(i.text)\n",
    "S_no1=S_no[0:29] \n",
    "\n",
    "Date=[]\n",
    "date=driver.find_elements_by_xpath(\"//td[@class='column-2']\")\n",
    "for i in date:\n",
    "    Date.append(i.text)\n",
    "Date1=Date[0:29]  \n",
    "\n",
    "Startup_name=[]\n",
    "name=driver.find_elements_by_xpath(\"//td[@class='column-3']\")\n",
    "for i in name:\n",
    "    Startup_name.append(i.text)\n",
    "Startup_name1=Startup_name[0:29]  \n",
    "\n",
    "Industry=[]\n",
    "industry=driver.find_elements_by_xpath(\"//td[@class='column-4']\")\n",
    "for i in industry:\n",
    "    Industry.append(i.text)\n",
    "Industry1=Industry[0:29]  \n",
    "\n",
    "sub_vertical=[]\n",
    "vertical=driver.find_elements_by_xpath(\"//td[@class='column-5']\")\n",
    "for i in vertical:\n",
    "    sub_vertical.append(i.text)\n",
    "sub_vertical1=sub_vertical[0:29]  \n",
    "\n",
    "City=[]\n",
    "city=driver.find_elements_by_xpath(\"//td[@class='column-6']\")\n",
    "for i in city:\n",
    "    City.append(i.text)\n",
    "City1=City[0:29]  \n",
    "\n",
    "Name=[]\n",
    "name=driver.find_elements_by_xpath(\"//td[@class='column-7']\")\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "Name1=Name[0:29] \n",
    "\n",
    "Type=[]\n",
    "types=driver.find_elements_by_xpath(\"//td[@class='column-8']\")\n",
    "for i in types:\n",
    "    Type.append(i.text)\n",
    "Type1=Type[0:29]  \n",
    "\n",
    "Amount=[]\n",
    "amount=driver.find_elements_by_xpath(\"//td[@class='column-9']\")\n",
    "for i in amount:\n",
    "    Amount.append(i.text)\n",
    "Amount1=Amount[0:29]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2946d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Funding_deals=pd.DataFrame({'S.no':S_no1,'Date':Date1,'Startup name':Startup_name1,'Industry':Industry1,'Sub Vertical':sub_vertical1,'City':City1,'Invester Name':Name1,'Investment Type':Type1,'Amount':Amount1})\n",
    "Funding_deals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcb9079",
   "metadata": {},
   "source": [
    "7. Write a program to scrap all the available details of best gaming laptops from digit.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9edb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.digit.in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836baa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "button=driver.find_element_by_xpath('/html/body/div[1]/div/div[4]/ul/li[3]/a')\n",
    "button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ff2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "button1=driver.find_element_by_xpath('/html/body/div[6]/div/div[2]/div[2]/ul/li[10]/a')\n",
    "button1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34040c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in driver.find_elements_by_xpath('//*[contains(@id,\"summtable\")]//tr'):\n",
    "    data = [item.text for item in table.find_elements_by_xpath(\".//*[self::th or self::td]\")]\n",
    "    print(data)\n",
    "    Laptop=data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8800c947",
   "metadata": {},
   "source": [
    "8. Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be \n",
    "    scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea854a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.forbes.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedb3125",
   "metadata": {},
   "outputs": [],
   "source": [
    "button=driver.find_element_by_xpath('/html/body/div[1]/header/nav/div[1]/button[1]')\n",
    "button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc2ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "button1=driver.find_element_by_xpath('/html/body/div[1]/header/nav/div[3]/ul/li[1]')\n",
    "button1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0900ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "button2=driver.find_element_by_xpath('/html/body/div[1]/header/nav/div[3]/ul/li[1]/div[2]/ul/li[2]')\n",
    "button2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b1ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "rank=driver.find_elements_by_xpath(\"//div[@class='rank']\")\n",
    "for i in rank:\n",
    "    Rank.append(i.text)\n",
    "Name=[]\n",
    "name=driver.find_elements_by_xpath(\"//div[@class='personName']\")\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "Net_worth=[]\n",
    "worth=driver.find_elements_by_xpath(\"//div[@class='netWorth']\")\n",
    "for i in worth:\n",
    "    Net_worth.append(i.text)\n",
    "Age=[]\n",
    "age=driver.find_elements_by_xpath(\"//div[@class='age']\")\n",
    "for i in age:\n",
    "    Age.append(i.text)\n",
    "Citizenship=[]\n",
    "citizenship=driver.find_elements_by_xpath(\"//div[@class='countryOfCitizenship']\")\n",
    "for i in citizenship:\n",
    "    Citizenship.append(i.text)\n",
    "Source=[]\n",
    "source=driver.find_elements_by_xpath(\"//div[@class='source-column']\")\n",
    "for i in source:\n",
    "    Source.append(i.text)\n",
    "Industry=[]\n",
    "industry=driver.find_elements_by_xpath(\"//div[@class='category']\")\n",
    "for i in industry:\n",
    "    Industry.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f9226",
   "metadata": {},
   "outputs": [],
   "source": [
    "billionaires=pd.DataFrame({'Rank':Rank,'Name':Name,'Net Worth':Net_worth,'Age':Age,'Citizenship':Citizenship,'Source':Source,'Industry':Industry})\n",
    "billionaires.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b407566",
   "metadata": {},
   "source": [
    "9. Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted from any YouTube Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c358d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "data1=[]\n",
    "wait = WebDriverWait(driver,15)\n",
    "driver.get(\"https://www.youtube.com/watch?v=kuhhT_cBtFU&t=2s\")\n",
    "\n",
    "for item in range(1): \n",
    "    wait.until(EC.visibility_of_element_located((By.TAG_NAME, \"body\"))).send_keys(Keys.END)\n",
    "    time.sleep(15)\n",
    "\n",
    "for comment in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#content\"))):\n",
    "    data.append(comment.text)\n",
    "    data_new=data[4:24]\n",
    "    \n",
    "for date in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#header-author\"))):\n",
    "    if date.text is None :\n",
    "        data1.append(\"--\") \n",
    "    else:\n",
    "        data1.append(date.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   \n",
    "df = pd.DataFrame({'comment':data_new,'Date':data1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a4d692",
   "metadata": {},
   "source": [
    "10. Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in \n",
    "“London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, \n",
    "overall reviews, privates from price, dorms from price, facilities and property description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c858b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.hostelworld.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c29b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "button=driver.find_element_by_xpath('//*[@id=\"search-input-field\"]')\n",
    "button.send_keys('London')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe57c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "button1=driver.find_element_by_xpath('//*[@id=\"predicted-search-results\"]/li[2]')\n",
    "button1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f915b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "button2=driver.find_element_by_xpath('//*[@id=\"search-button\"]')\n",
    "button2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ce4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "name=driver.find_elements_by_xpath(\"//h2[@class='title title-6']\")\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "Distance=[]\n",
    "distance=driver.find_elements_by_xpath(\"//div[@class='subtitle body-3']\")\n",
    "for i in distance:\n",
    "    Distance.append(i.text)\n",
    "Ratings=[]\n",
    "ratings=driver.find_elements_by_xpath(\"//div[@class='score orange big']\")\n",
    "for i in ratings:\n",
    "    Ratings.append(i.text)\n",
    "Review=[]\n",
    "review=driver.find_elements_by_xpath(\"//div[@class='reviews']\")\n",
    "for i in review:\n",
    "    Review.append(i.text)\n",
    "Pprice=[]\n",
    "price=driver.find_elements_by_xpath(\"//div[@class='price-col']\")\n",
    "for i in price:\n",
    "    Pprice.append(i.text)\n",
    "Pprice1=Pprice[0:60:2]\n",
    "Dprice=[]\n",
    "price=driver.find_elements_by_xpath(\"//div[@class='price-col']\")\n",
    "for i in price:\n",
    "    Dprice.append(i.text)\n",
    "Dprice1=Dprice[1:60:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcca0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hostel=pd.DataFrame({'Name':Name,'Distance':Distance,'Ratings':Ratings,'Review':Review,'Pprice':Pprice1,'Dprice':Dprice1})\n",
    "hostel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a38954e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
